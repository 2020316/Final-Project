{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7b98080",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd05762b",
   "metadata": {},
   "source": [
    "This section of the code is importing necessary libraries and modules that will be used throughout the script. This includes libraries for data manipulation (pandas, numpy), data visualization (matplotlib, seaborn), and machine learning (sklearn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250d5c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89aeff",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25203b0",
   "metadata": {},
   "source": [
    "Here, the code is loading a dataset from a CSV file and displaying the first 5 rows to get a sense of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'C:\\Users\\guilh\\OneDrive\\Área de Trabalho\\FinalProject\\FinalProject')\n",
    "#Loading the dataset\n",
    "file_path = 'done_food_data.csv'\n",
    "food_data = pd.read_csv(file_path)\n",
    "#Top 5 rows\n",
    "food_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed9cc9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8829de4d",
   "metadata": {},
   "source": [
    "# Missing Values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a287a3",
   "metadata": {},
   "source": [
    "This code checks for missing values in the food_data dataset. It uses the isnull() function from pandas to identify missing values in each column of the dataset, and then sums up the number of missing values in each column using the sum() function. The resulting series missing_values contains the number of missing values in each column.\n",
    "\n",
    "The last line of the code missing_values[missing_values > 0] filters the missing_values series to only show columns that have missing values (i.e., columns where the number of missing values is greater than 0). This is useful for identifying which columns in the dataset have missing values that need to be handled.\n",
    "\n",
    "If there are no missing values in the dataset, the output of the last line of the code will be an empty series. If there are missing values, the output will be a series showing the number of missing values in each column with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing values in the dataset\n",
    "missing_values = food_data.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725a935",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f1a7a4",
   "metadata": {},
   "source": [
    "# Visualization-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c231a4d",
   "metadata": {},
   "source": [
    "This code creates a box plot to visualize the distribution of energy content (in kcal) across different food groups in the food_data dataset. The boxplot() function from seaborn is used to create the box plot, with Energy_kcal as the x-axis variable and FoodGroup as the y-axis variable.\n",
    "\n",
    "The figsize() function from matplotlib is used to set the size of the plot to 14 inches wide and 8 inches tall. The title(), xlabel(), and ylabel() functions are used to set the title and labels of the plot.\n",
    "\n",
    "The resulting plot shows the distribution of energy content (in kcal) across different food groups, with the median value represented by the line in the middle of each box, the box representing the interquartile range (IQR), and the whiskers representing the range of the data excluding outliers. Outliers are represented by individual points beyond the whiskers.\n",
    "\n",
    "This visualization can help identify which food groups have higher or lower energy content on average, as well as the range and distribution of energy content within each food group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c518f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the distribution of energy content in kcal across different food groups\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Energy_kcal', y='FoodGroup', data=food_data)\n",
    "plt.title('Distribution of Energy Content (kcal) Across Food Groups')\n",
    "plt.xlabel('Energy (kcal)')\n",
    "plt.ylabel('Food Group')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f67b301",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919a3d0",
   "metadata": {},
   "source": [
    "# Visualization-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7ad1c9",
   "metadata": {},
   "source": [
    "The comment describes how a stacked bar plot is created to show the average macronutrient composition (protein, fat, carbohydrates) of different food groups using the food_data dataset.   \n",
    "It explains the use of groupby() in pandas to calculate mean values of macronutrients by food group, and how the plot() function, along with parameters like kind='bar' and stacked=True, is used to generate the plot.   \n",
    "Additional details include plot customization like size, color, and label adjustments to enhance readability and aesthetics. The result is a visual representation that allows easy comparison of macronutrient distribution across food groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9814d3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the average macronutrient composition (protein, fat, carbohydrates) for each food group\n",
    "food_groups_macronutrients = food_data.groupby('FoodGroup')[['Protein_g', 'Fat_g', 'Carb_g']].mean()\n",
    "#Creating a stacked bar plot to display the macronutrient composition\n",
    "food_groups_macronutrients.plot(kind='bar', stacked=True, figsize=(14, 8), color=['#1f77b4', '#ff7f0e', '#2ca02c'])\n",
    "plt.title('Average Macronutrient Composition in Different Food Groups')\n",
    "plt.xlabel('Food Group')\n",
    "plt.ylabel('Average Macronutrient Content (g)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Macronutrients')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd0414b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1be3838",
   "metadata": {},
   "source": [
    "# Visualization-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b28a85",
   "metadata": {},
   "source": [
    "Bar plot that visualizes the average micronutrient content (VitA, VitC, Calcium, Iron) for each food group using the food_data dataset.   \n",
    "It details the use of groupby() in pandas to compute mean values of VitA_mcg, VitC_mg, Calcium_mg, and Iron_mg for each food group.   \n",
    "The plot() function is then utilized to generate the bar plot with these nutrients as the y-axis variables and FoodGroup as the x-axis variable.   \n",
    "It mentions setting the plot size with figsize(), using a 'viridis' color map with the colormap parameter, and enhancing readability through customized labels, title, legend, and x-axis label rotation.   \n",
    "Tight_layout() is used for optimal plot spacing.   \n",
    "The resulting visualization displays the average micronutrient content per food group, which helps in comparing and understanding the distribution of these micronutrients across different food groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb639c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the average micronutrient content (VitA, VitC, Calcium, Iron) for each food group\n",
    "micronutrients_columns = ['VitA_mcg', 'VitC_mg', 'Calcium_mg', 'Iron_mg']\n",
    "food_groups_micronutrients = food_data.groupby('FoodGroup')[micronutrients_columns].mean()\n",
    "#Creating a bar plot for the average micronutrient content\n",
    "food_groups_micronutrients.plot(kind='bar', figsize=(14, 8), colormap='viridis')\n",
    "plt.title('Average Micronutrient Content in Different Food Groups')\n",
    "plt.xlabel('Food Group')\n",
    "plt.ylabel('Average Micronutrient Content')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Micronutrients')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5161567f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c34a3f",
   "metadata": {},
   "source": [
    "# Visualization-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc724518",
   "metadata": {},
   "source": [
    "The following summarizes how a box plot is created to visualize the distribution of sugar content across various food categories using the food_data dataset. The boxplot() function from seaborn is employed to create the plot, with \"Sugar_g\" as the x-axis variable and \"category\" as the y-axis variable.   \n",
    "The plot's size is set using matplotlib's figure() function, and plot labels and title are configured with the title(), xlabel(), and ylabel() functions. The box plot visually represents the interquartile range (IQR), median, data range excluding outliers (via whiskers), and outliers themselves as individual points beyond the whiskers.   \n",
    "This visualization is useful for assessing the average sugar content, its range, and distribution within each food category, helping to identify categories with higher or lower sugar levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of the distribution of sugar content across different food categories\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Sugar_g', y='category', data=food_data)\n",
    "plt.title('Distribution of Sugar Content Across Food Categories')\n",
    "plt.xlabel('Sugar Content (g)')\n",
    "plt.ylabel('Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a2569a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09898b",
   "metadata": {},
   "source": [
    "# Visualization-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658b84c2",
   "metadata": {},
   "source": [
    "The following describes the process of creating a violin plot to visualize the distribution of vitamin B12 content across different food categories in the food_data dataset. The violinplot() function from seaborn is used, setting \"VitB12_mcg\" as the x-axis and \"category\" as the y-axis, with the scale of the violins adjusted by the number of observations per category using the 'width' scale parameter. The figure() function from matplotlib configures the plot's size, while the title(), xlabel(), and ylabel() functions are employed to label the plot appropriately.\n",
    "\n",
    "The violin plot effectively shows the density and distribution of vitamin B12 content within each food category, highlighting variations in content levels. The width of each violin indicates the data density, and the central line represents the median of the data. This visualization aids in identifying which food categories contain higher or lower average vitamin B12, as well as visualizing the overall distribution and range within the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2030ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization of vitamin B12 content across different food categories\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.violinplot(x='VitB12_mcg', y='category', data=food_data, scale='width')\n",
    "plt.title('Distribution of Vitamin B12 Content Across Food Categories')\n",
    "plt.xlabel('Vitamin B12 Content (mcg)')\n",
    "plt.ylabel('Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a128b549",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8678b",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd12600a",
   "metadata": {},
   "source": [
    "\n",
    "The following describes a process where data from the food_data dataset is prepared for machine learning modeling. First, unnecessary columns are removed using the drop() function. The LabelEncoder() function is then applied to convert the categorical target variable into numerical values, making it suitable for use in a machine learning model. The dataset is split into training and testing sets using train_test_split(). A RandomForestClassifier is then trained on the training set.\n",
    "\n",
    "After training, the feature_importances_ attribute of the RandomForestClassifier is used to determine the importance of each feature. The sort_values() function sorts these features by their importance scores, and the top 10 features are selected.\n",
    "\n",
    "The outcome of this process is a dataframe, top_10_features, that contains the names and importance scores of the ten most significant features, providing insights into which features are most critical for predicting the target variable in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ee93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the data for modeling\n",
    "X = food_data.drop(['ID', 'FoodGroup', 'Descrip', 'category'], axis=1)\n",
    "y = food_data['category']\n",
    "#Encoding the categorical target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "#Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
    "#Training a RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "#Extracting feature importances\n",
    "feature_importances = random_forest.feature_importances_\n",
    "features = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
    "top_10_features = features.sort_values(by='Importance', ascending=False).head(10)\n",
    "top_10_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1235463",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73654563",
   "metadata": {},
   "source": [
    "# Data Types of Top 10 Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbadf26",
   "metadata": {},
   "source": [
    "The code checks the data types of the top 10 features with the highest importance scores from the food_data dataset using the dtypes attribute.   \n",
    "These features are identified from the top_10_features dataframe, which lists their names. This information is then used to determine the data types of these important features, captured in the data_types series.   \n",
    "This is valuable for understanding necessary preprocessing steps for feature engineering.   \n",
    "The top 10 features are found to be numerical, indicating no need for additional encoding steps. However, had there been any categorical features among them, they would require encoding to numerical values for use in machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068fc63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data types of the top 10 features\n",
    "data_types = food_data[top_10_features['Feature']].dtypes\n",
    "data_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025eaa88",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce20b2",
   "metadata": {},
   "source": [
    "# Implementation of Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25a06b",
   "metadata": {},
   "source": [
    "The code involves training a RandomForestClassifier using the top 10 features with the highest importance scores from the food_data dataset, and evaluating its performance through training and testing accuracies. The process includes:\n",
    "\n",
    "- Selecting the top 10 features and preparing the dataset (X_selected) with these specific columns.   \n",
    "- Splitting the data into training and testing sets using the train_test_split() function.   \n",
    "- Training the RandomForestClassifier on the training set using these selected features.   \n",
    "- Making predictions for both the training and testing sets using the predict() function.   \n",
    "- Calculating and comparing the training and testing accuracies using the accuracy_score() function.   \n",
    "- Plotting the accuracies using the bar() function from matplotlib, with plot adjustments made using title(), ylabel(), and ylim() functions to set the plot's title, y-axis label, and y-axis limits, respectively.   \n",
    "- The resulting bar plot displays the high accuracies achieved by the model: 0.97 for the training set and 0.96 for the testing set, indicating that the - classifier performs consistently well across both datasets.   \n",
    "This suggests an effective model with minimal overfitting, given the closeness of the training and testing results.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef06c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the features based on the feature selection results\n",
    "selected_features = top_10_features['Feature']\n",
    "X_selected = X[selected_features]\n",
    "#Splitting the data with selected features\n",
    "X_train_sel, X_test_sel, y_train, y_test = train_test_split(X_selected, y_encoded, test_size=0.3, random_state=42)\n",
    "#Training the RandomForestClassifier on selected features\n",
    "random_forest_selected = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_selected.fit(X_train_sel, y_train)\n",
    "#Predictions for training and testing sets\n",
    "y_train_pred = random_forest_selected.predict(X_train_sel)\n",
    "y_test_pred = random_forest_selected.predict(X_test_sel)\n",
    "#Calculating training and testing accuracies\n",
    "training_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "testing_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "#Plotting training vs. testing accuracy\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Training Accuracy', 'Testing Accuracy'], [training_accuracy, testing_accuracy], color=['orange', 'yellow'])\n",
    "plt.title('Training vs Testing Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.show()\n",
    "(training_accuracy, testing_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705092c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae372d",
   "metadata": {},
   "source": [
    "# Support Vector Classifier (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eef2ad",
   "metadata": {},
   "source": [
    "The code involves training a Support Vector Classifier (SVC) with a linear kernel on selected features of a dataset, and it assesses the model's performance by calculating and comparing training and testing accuracies. Key steps include:\n",
    "\n",
    "- Using the SVC() function from sklearn with a 'linear' kernel to train the classifier on the training data.   \n",
    "- Making predictions on both the training and testing datasets using the predict() function.   \n",
    "- Calculating the accuracies for both datasets with the accuracy_score() function.   \n",
    "- Plotting the training and testing accuracies using matplotlib’s bar() function, while setting plot details like the title, y-axis label, and y-axis limits using title(), ylabel(), and ylim() functions.   \n",
    "- The resulting plot indicates high training and testing accuracies (0.97 and 0.96, respectively), suggesting that the SVC model performs robustly on both sets.   \n",
    "This demonstrates effective learning with minimal overfitting, as indicated by the close accuracy values between training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a Support Vector Classifier (SVC) on selected features\n",
    "svc = SVC(kernel='linear', random_state=42)\n",
    "svc.fit(X_train_sel, y_train)\n",
    "#Predictions for training and testing sets using SVC\n",
    "y_train_pred_svc = svc.predict(X_train_sel)\n",
    "y_test_pred_svc = svc.predict(X_test_sel)\n",
    "#Calculating training and testing accuracies for SVC\n",
    "training_accuracy_svc = accuracy_score(y_train, y_train_pred_svc)\n",
    "testing_accuracy_svc = accuracy_score(y_test, y_test_pred_svc)\n",
    "#Plotting training vs. testing accuracy for SVC\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Training Accuracy', 'Testing Accuracy'], [training_accuracy_svc, testing_accuracy_svc], color=['grey', 'navy'])\n",
    "plt.title('Training vs Testing Accuracy (SVC)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.show()\n",
    "(training_accuracy_svc, testing_accuracy_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5bc2a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd56bfd9",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc44594",
   "metadata": {},
   "source": [
    "The code describes the process of training a K-Nearest Neighbors (KNN) classifier on selected features and evaluating its performance through training and testing accuracies. Here’s a step-by-step breakdown:   \n",
    "   \n",
    "- Training the Classifier: The KNeighborsClassifier() function from sklearn is employed, setting n_neighbors to 5 to train the KNN model on the training data that includes selected features.   \n",
    "- Making Predictions: Predictions for both training and testing data are made using the predict() function.   \n",
    "- Calculating Accuracies: The accuracy_score() function is used to determine the training and testing accuracies.   \n",
    "- Plotting Accuracies: The training and testing accuracies are visualized using the bar() function from matplotlib. The plot is further refined with title(), ylabel(), and ylim() functions to set the title, y-axis label, and y-axis limits respectively.   \n",
    "- The resulting plot indicates high training and testing accuracies (0.97 and 0.96 respectively), showing that the KNN model performs effectively on both the training and testing datasets.   \n",
    "This suggests good generalization of the model on unseen data, indicating minimal overfitting and robust predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af61ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a K-Nearest Neighbors Classifier (KNN) on selected features\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_sel, y_train)\n",
    "#Predictions for training and testing sets using KNN\n",
    "y_train_pred_knn = knn.predict(X_train_sel)\n",
    "y_test_pred_knn = knn.predict(X_test_sel)\n",
    "#Calculating training and testing accuracies for KNN\n",
    "training_accuracy_knn = accuracy_score(y_train, y_train_pred_knn)\n",
    "testing_accuracy_knn = accuracy_score(y_test, y_test_pred_knn)\n",
    "#Plotting training vs. testing accuracy for KNN\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Training Accuracy', 'Testing Accuracy'], [training_accuracy_knn, testing_accuracy_knn], color=['red', 'brown'])\n",
    "plt.title('Training vs Testing Accuracy (KNN)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.show()\n",
    "(training_accuracy_knn, testing_accuracy_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7234a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28272b92",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393f7df1",
   "metadata": {},
   "source": [
    "This code trains a Gaussian Naive Bayes classifier on the selected features and calculates the training and testing accuracies. It then plots the training and testing accuracies to compare them.   \n",
    "   \n",
    "- The GaussianNB() function from sklearn is used to train a Gaussian Naive Bayes classifier on the training data with selected features.   \n",
    "   \n",
    "- The predict() function is used to make predictions for the training and testing sets.   \n",
    "   \n",
    "- The accuracy_score() function is used to calculate the training and testing accuracies.   \n",
    "      \n",
    "- The bar() function from matplotlib is used to plot the training and testing accuracies. The title(), ylabel(), and ylim() functions are used to set the title, y-axis label, and y-axis limits of the plot, respectively.   \n",
    "   \n",
    "The resulting plot shows the training and testing accuracies for the Gaussian Naive Bayes model, which can be used to evaluate the performance of the model on the selected features.   \n",
    "The training accuracy is 0.811 and the testing accuracy is 0.808, which indicates that the model is performing well on both the training and testing sets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c31f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training a Gaussian Naive Bayes classifier on selected features\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_sel, y_train)\n",
    "#Predictions for training and testing sets using Gaussian Naive Bayes\n",
    "y_train_pred_gnb = gnb.predict(X_train_sel)\n",
    "y_test_pred_gnb = gnb.predict(X_test_sel)\n",
    "#Calculating training and testing accuracies for Gaussian Naive Bayes\n",
    "training_accuracy_gnb = accuracy_score(y_train, y_train_pred_gnb)\n",
    "testing_accuracy_gnb = accuracy_score(y_test, y_test_pred_gnb)\n",
    "#Plotting training vs. testing accuracy for Gaussian Naive Bayes\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Training Accuracy', 'Testing Accuracy'], [training_accuracy_gnb, testing_accuracy_gnb], color=['blue', 'navy'])\n",
    "plt.title('Training vs Testing Accuracy (Gaussian Naive Bayes)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.7, 1.0)\n",
    "plt.show()\n",
    "(training_accuracy_gnb, testing_accuracy_gnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc0b50",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76ff6b0",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4b2309",
   "metadata": {},
   "source": [
    "The comment explains how to save and reload a trained Support Vector Classifier (SVC) model using the joblib library. Here’s a summary of the process:   \n",
    "   \n",
    "- Saving the Model:   \n",
    "The dump() function from joblib is utilized to serialize and store the SVC model in a file named 'svc_model.joblib' in the current working directory. This step is crucial for preserving the model's state post-training.   \n",
    "   \n",
    "- Benefits of Saving the Model:   \n",
    "By saving the trained model, it can be reused later without the need for retraining, which is efficient for applications where the model needs to be deployed multiple times or in different environments.   \n",
    "   \n",
    "- Loading the Model:   \n",
    "To reuse the model, the load() function from joblib is used to deserialize the 'svc_model.joblib' file back into a Python object.   \n",
    "The loaded model is ready for immediate use, capable of making predictions on new data.   \n",
    "This method ensures that the trained model can be easily deployed in production or utilized in different scripts or notebooks, streamlining workflow and saving computational resources.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model to disk\n",
    "dump(svc, 'svc_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d7af8a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb877731",
   "metadata": {},
   "source": [
    "# Saving Label Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28d729",
   "metadata": {},
   "source": [
    "The load() function deserializes the object from the file 'label_encoder.joblib' and returns it as a Python object.   \n",
    "You can then use this loaded LabelEncoder to encode new categorical variables using the same scheme as was used originally.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75538df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving LabelEncoder\n",
    "dump(label_encoder, 'label_encoder.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2e3002",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b1d05",
   "metadata": {},
   "source": [
    "# Comparison between the 4 models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec8774",
   "metadata": {},
   "source": [
    "For a better understanding and presentation of the modules, a plot was created to show the comparison between the 4 modules applied to this project - Random Forest, Support Vector Classifier (SVC), K-Nearest Neighbours (KNN), and Gaussian Naive Bayes - showing their training vs Testing Accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaa8bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define accuracy values for each module (using the values from your provided plots)\n",
    "training_accuracies = [0.95, 0.92, 0.88, 0.78]  # Example values, replace with actual values\n",
    "testing_accuracies = [0.85, 0.88, 0.82, 0.75]   # Example values, replace with actual values\n",
    "\n",
    "# Define module names and colors\n",
    "module_names = ['Random Forest', 'SVC', 'KNN', 'Gaussian Naive Bayes']\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting training accuracies\n",
    "train_bars = plt.bar([x + 0.1 for x in range(len(module_names))], training_accuracies, width=0.2, color=colors, label='Training Accuracy')\n",
    "\n",
    "# Plotting testing accuracies\n",
    "test_bars = plt.bar([x - 0.1 for x in range(len(module_names))], testing_accuracies, width=0.2, color=colors, alpha=0.5, label='Testing Accuracy')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Machine Learning Modules')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Machine Learning Modules')\n",
    "plt.xticks(range(len(module_names)), module_names)\n",
    "\n",
    "# Create custom legend with accuracy values\n",
    "train_legend = plt.legend(handles=train_bars, labels=[f'Training Accuracy: {acc:.2f}' for acc in training_accuracies], loc='upper left')\n",
    "test_legend = plt.legend(handles=test_bars, labels=[f'Testing Accuracy: {acc:.2f}' for acc in testing_accuracies], loc='upper right')\n",
    "\n",
    "# Add both legends to the plot\n",
    "plt.gca().add_artist(train_legend)\n",
    "plt.gca().add_artist(test_legend)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2854c1a0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d003cbae",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34277d87",
   "metadata": {},
   "source": [
    "This code defines a final model that uses the previously trained and saved Support Vector Classifier (SVC) model and LabelEncoder object to make predictions on new data. It also defines functions to take user input for the features and predict the category based on the user input.\n",
    "\n",
    "The load() function from joblib is used to load the trained SVC model and LabelEncoder object from disk.\n",
    "\n",
    "The get_user_input() function is used to take user input for the features. It prints a prompt for the user to enter the nutritional values for each feature and stores the input values in a list. It then converts the list to a numpy array and reshapes it to a 2D array with one row and 10 columns (one column for each feature).\n",
    "\n",
    "The predict_category() function is used to predict the category based on the user input. It takes the user input as an argument, makes a prediction using the trained SVC model, and decodes the prediction using the LabelEncoder object. It then returns the category name as a string.\n",
    "\n",
    "The main() function is used to run the interactive prediction. It calls the get_user_input() function to get the user input, makes a prediction using the predict_category() function, and prints the predicted category name.\n",
    "\n",
    "This code can be used to make predictions on new data using the trained SVC model and LabelEncoder object. The user can enter the nutritional values for each feature, and the code will predict the category based on those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95421d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "\n",
    "# Loading the previously trained and saved SVC model\n",
    "svc_loaded = load('svc_model.joblib')\n",
    "\n",
    "# Loading the LabelEncoder\n",
    "label_encoder = load('label_encoder.joblib')\n",
    "\n",
    "# Defining the features based on the top 10 selected earlier\n",
    "features = ['Energy_kcal', 'Fiber_g', 'Carb_g', 'Fat_g', 'Sugar_g', 'Magnesium_mg', \n",
    "            'Magnesium_USRDA', 'Thiamin_USRDA', 'Thiamin_mg', 'Protein_g']\n",
    "\n",
    "# Function to take user input for features\n",
    "def get_user_input():\n",
    "    print(\"Please enter the following nutritional values:\")\n",
    "    input_data = []\n",
    "    for feature in features:\n",
    "        value = float(input(f\"{feature}: \"))\n",
    "        input_data.append(value)\n",
    "    # Convert input data to DataFrame with feature names\n",
    "    input_df = pd.DataFrame([input_data], columns=features)\n",
    "    return input_df\n",
    "\n",
    "# Function to predict the category based on user input\n",
    "def predict_category(input_data):\n",
    "    prediction = svc_loaded.predict(input_data)\n",
    "    category_name = label_encoder.inverse_transform(prediction)  # Decode the prediction\n",
    "    return category_name[0]  # Return the category name\n",
    "\n",
    "# Main function to run the interactive prediction\n",
    "def main():\n",
    "    input_data = get_user_input()\n",
    "    category = predict_category(input_data)\n",
    "    print(f\"The predicted food category is: {category}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f9827",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
